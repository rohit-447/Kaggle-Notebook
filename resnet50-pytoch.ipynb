{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T16:12:27.853753Z","iopub.execute_input":"2025-08-23T16:12:27.854765Z","iopub.status.idle":"2025-08-23T16:12:28.248367Z","shell.execute_reply.started":"2025-08-23T16:12:27.854724Z","shell.execute_reply":"2025-08-23T16:12:28.247293Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nmodel_original=models.resnet50(pretrained=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T16:12:28.250311Z","iopub.execute_input":"2025-08-23T16:12:28.250897Z","iopub.status.idle":"2025-08-23T16:12:39.330578Z","shell.execute_reply.started":"2025-08-23T16:12:28.250860Z","shell.execute_reply":"2025-08-23T16:12:39.329405Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model_original, (3,64,64))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T16:12:39.331593Z","iopub.execute_input":"2025-08-23T16:12:39.332066Z","iopub.status.idle":"2025-08-23T16:12:39.606446Z","shell.execute_reply.started":"2025-08-23T16:12:39.332039Z","shell.execute_reply":"2025-08-23T16:12:39.605402Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           9,408\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n         MaxPool2d-4           [-1, 64, 16, 16]               0\n            Conv2d-5           [-1, 64, 16, 16]           4,096\n       BatchNorm2d-6           [-1, 64, 16, 16]             128\n              ReLU-7           [-1, 64, 16, 16]               0\n            Conv2d-8           [-1, 64, 16, 16]          36,864\n       BatchNorm2d-9           [-1, 64, 16, 16]             128\n             ReLU-10           [-1, 64, 16, 16]               0\n           Conv2d-11          [-1, 256, 16, 16]          16,384\n      BatchNorm2d-12          [-1, 256, 16, 16]             512\n           Conv2d-13          [-1, 256, 16, 16]          16,384\n      BatchNorm2d-14          [-1, 256, 16, 16]             512\n             ReLU-15          [-1, 256, 16, 16]               0\n       Bottleneck-16          [-1, 256, 16, 16]               0\n           Conv2d-17           [-1, 64, 16, 16]          16,384\n      BatchNorm2d-18           [-1, 64, 16, 16]             128\n             ReLU-19           [-1, 64, 16, 16]               0\n           Conv2d-20           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-21           [-1, 64, 16, 16]             128\n             ReLU-22           [-1, 64, 16, 16]               0\n           Conv2d-23          [-1, 256, 16, 16]          16,384\n      BatchNorm2d-24          [-1, 256, 16, 16]             512\n             ReLU-25          [-1, 256, 16, 16]               0\n       Bottleneck-26          [-1, 256, 16, 16]               0\n           Conv2d-27           [-1, 64, 16, 16]          16,384\n      BatchNorm2d-28           [-1, 64, 16, 16]             128\n             ReLU-29           [-1, 64, 16, 16]               0\n           Conv2d-30           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-31           [-1, 64, 16, 16]             128\n             ReLU-32           [-1, 64, 16, 16]               0\n           Conv2d-33          [-1, 256, 16, 16]          16,384\n      BatchNorm2d-34          [-1, 256, 16, 16]             512\n             ReLU-35          [-1, 256, 16, 16]               0\n       Bottleneck-36          [-1, 256, 16, 16]               0\n           Conv2d-37          [-1, 128, 16, 16]          32,768\n      BatchNorm2d-38          [-1, 128, 16, 16]             256\n             ReLU-39          [-1, 128, 16, 16]               0\n           Conv2d-40            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-41            [-1, 128, 8, 8]             256\n             ReLU-42            [-1, 128, 8, 8]               0\n           Conv2d-43            [-1, 512, 8, 8]          65,536\n      BatchNorm2d-44            [-1, 512, 8, 8]           1,024\n           Conv2d-45            [-1, 512, 8, 8]         131,072\n      BatchNorm2d-46            [-1, 512, 8, 8]           1,024\n             ReLU-47            [-1, 512, 8, 8]               0\n       Bottleneck-48            [-1, 512, 8, 8]               0\n           Conv2d-49            [-1, 128, 8, 8]          65,536\n      BatchNorm2d-50            [-1, 128, 8, 8]             256\n             ReLU-51            [-1, 128, 8, 8]               0\n           Conv2d-52            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-53            [-1, 128, 8, 8]             256\n             ReLU-54            [-1, 128, 8, 8]               0\n           Conv2d-55            [-1, 512, 8, 8]          65,536\n      BatchNorm2d-56            [-1, 512, 8, 8]           1,024\n             ReLU-57            [-1, 512, 8, 8]               0\n       Bottleneck-58            [-1, 512, 8, 8]               0\n           Conv2d-59            [-1, 128, 8, 8]          65,536\n      BatchNorm2d-60            [-1, 128, 8, 8]             256\n             ReLU-61            [-1, 128, 8, 8]               0\n           Conv2d-62            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-63            [-1, 128, 8, 8]             256\n             ReLU-64            [-1, 128, 8, 8]               0\n           Conv2d-65            [-1, 512, 8, 8]          65,536\n      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n             ReLU-67            [-1, 512, 8, 8]               0\n       Bottleneck-68            [-1, 512, 8, 8]               0\n           Conv2d-69            [-1, 128, 8, 8]          65,536\n      BatchNorm2d-70            [-1, 128, 8, 8]             256\n             ReLU-71            [-1, 128, 8, 8]               0\n           Conv2d-72            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-73            [-1, 128, 8, 8]             256\n             ReLU-74            [-1, 128, 8, 8]               0\n           Conv2d-75            [-1, 512, 8, 8]          65,536\n      BatchNorm2d-76            [-1, 512, 8, 8]           1,024\n             ReLU-77            [-1, 512, 8, 8]               0\n       Bottleneck-78            [-1, 512, 8, 8]               0\n           Conv2d-79            [-1, 256, 8, 8]         131,072\n      BatchNorm2d-80            [-1, 256, 8, 8]             512\n             ReLU-81            [-1, 256, 8, 8]               0\n           Conv2d-82            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-83            [-1, 256, 4, 4]             512\n             ReLU-84            [-1, 256, 4, 4]               0\n           Conv2d-85           [-1, 1024, 4, 4]         262,144\n      BatchNorm2d-86           [-1, 1024, 4, 4]           2,048\n           Conv2d-87           [-1, 1024, 4, 4]         524,288\n      BatchNorm2d-88           [-1, 1024, 4, 4]           2,048\n             ReLU-89           [-1, 1024, 4, 4]               0\n       Bottleneck-90           [-1, 1024, 4, 4]               0\n           Conv2d-91            [-1, 256, 4, 4]         262,144\n      BatchNorm2d-92            [-1, 256, 4, 4]             512\n             ReLU-93            [-1, 256, 4, 4]               0\n           Conv2d-94            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-95            [-1, 256, 4, 4]             512\n             ReLU-96            [-1, 256, 4, 4]               0\n           Conv2d-97           [-1, 1024, 4, 4]         262,144\n      BatchNorm2d-98           [-1, 1024, 4, 4]           2,048\n             ReLU-99           [-1, 1024, 4, 4]               0\n      Bottleneck-100           [-1, 1024, 4, 4]               0\n          Conv2d-101            [-1, 256, 4, 4]         262,144\n     BatchNorm2d-102            [-1, 256, 4, 4]             512\n            ReLU-103            [-1, 256, 4, 4]               0\n          Conv2d-104            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-105            [-1, 256, 4, 4]             512\n            ReLU-106            [-1, 256, 4, 4]               0\n          Conv2d-107           [-1, 1024, 4, 4]         262,144\n     BatchNorm2d-108           [-1, 1024, 4, 4]           2,048\n            ReLU-109           [-1, 1024, 4, 4]               0\n      Bottleneck-110           [-1, 1024, 4, 4]               0\n          Conv2d-111            [-1, 256, 4, 4]         262,144\n     BatchNorm2d-112            [-1, 256, 4, 4]             512\n            ReLU-113            [-1, 256, 4, 4]               0\n          Conv2d-114            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-115            [-1, 256, 4, 4]             512\n            ReLU-116            [-1, 256, 4, 4]               0\n          Conv2d-117           [-1, 1024, 4, 4]         262,144\n     BatchNorm2d-118           [-1, 1024, 4, 4]           2,048\n            ReLU-119           [-1, 1024, 4, 4]               0\n      Bottleneck-120           [-1, 1024, 4, 4]               0\n          Conv2d-121            [-1, 256, 4, 4]         262,144\n     BatchNorm2d-122            [-1, 256, 4, 4]             512\n            ReLU-123            [-1, 256, 4, 4]               0\n          Conv2d-124            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-125            [-1, 256, 4, 4]             512\n            ReLU-126            [-1, 256, 4, 4]               0\n          Conv2d-127           [-1, 1024, 4, 4]         262,144\n     BatchNorm2d-128           [-1, 1024, 4, 4]           2,048\n            ReLU-129           [-1, 1024, 4, 4]               0\n      Bottleneck-130           [-1, 1024, 4, 4]               0\n          Conv2d-131            [-1, 256, 4, 4]         262,144\n     BatchNorm2d-132            [-1, 256, 4, 4]             512\n            ReLU-133            [-1, 256, 4, 4]               0\n          Conv2d-134            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-135            [-1, 256, 4, 4]             512\n            ReLU-136            [-1, 256, 4, 4]               0\n          Conv2d-137           [-1, 1024, 4, 4]         262,144\n     BatchNorm2d-138           [-1, 1024, 4, 4]           2,048\n            ReLU-139           [-1, 1024, 4, 4]               0\n      Bottleneck-140           [-1, 1024, 4, 4]               0\n          Conv2d-141            [-1, 512, 4, 4]         524,288\n     BatchNorm2d-142            [-1, 512, 4, 4]           1,024\n            ReLU-143            [-1, 512, 4, 4]               0\n          Conv2d-144            [-1, 512, 2, 2]       2,359,296\n     BatchNorm2d-145            [-1, 512, 2, 2]           1,024\n            ReLU-146            [-1, 512, 2, 2]               0\n          Conv2d-147           [-1, 2048, 2, 2]       1,048,576\n     BatchNorm2d-148           [-1, 2048, 2, 2]           4,096\n          Conv2d-149           [-1, 2048, 2, 2]       2,097,152\n     BatchNorm2d-150           [-1, 2048, 2, 2]           4,096\n            ReLU-151           [-1, 2048, 2, 2]               0\n      Bottleneck-152           [-1, 2048, 2, 2]               0\n          Conv2d-153            [-1, 512, 2, 2]       1,048,576\n     BatchNorm2d-154            [-1, 512, 2, 2]           1,024\n            ReLU-155            [-1, 512, 2, 2]               0\n          Conv2d-156            [-1, 512, 2, 2]       2,359,296\n     BatchNorm2d-157            [-1, 512, 2, 2]           1,024\n            ReLU-158            [-1, 512, 2, 2]               0\n          Conv2d-159           [-1, 2048, 2, 2]       1,048,576\n     BatchNorm2d-160           [-1, 2048, 2, 2]           4,096\n            ReLU-161           [-1, 2048, 2, 2]               0\n      Bottleneck-162           [-1, 2048, 2, 2]               0\n          Conv2d-163            [-1, 512, 2, 2]       1,048,576\n     BatchNorm2d-164            [-1, 512, 2, 2]           1,024\n            ReLU-165            [-1, 512, 2, 2]               0\n          Conv2d-166            [-1, 512, 2, 2]       2,359,296\n     BatchNorm2d-167            [-1, 512, 2, 2]           1,024\n            ReLU-168            [-1, 512, 2, 2]               0\n          Conv2d-169           [-1, 2048, 2, 2]       1,048,576\n     BatchNorm2d-170           [-1, 2048, 2, 2]           4,096\n            ReLU-171           [-1, 2048, 2, 2]               0\n      Bottleneck-172           [-1, 2048, 2, 2]               0\nAdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n          Linear-174                 [-1, 1000]       2,049,000\n================================================================\nTotal params: 25,557,032\nTrainable params: 25,557,032\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.05\nForward/backward pass size (MB): 23.41\nParams size (MB): 97.49\nEstimated Total Size (MB): 120.95\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class BottleNeck(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        expansion = 4\n        \n        super(BottleNeck, self).__init__()\n        self.conv1=nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.b1=nn.BatchNorm2d(out_channels)\n        self.conv2=nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.b2=nn.BatchNorm2d(out_channels)\n        self.conv3=nn.Conv2d(out_channels, out_channels*expansion, kernel_size=1, bias=False)\n        self.b3=nn.BatchNorm2d(out_channels*expansion)\n\n        self.relu=nn.ReLU()\n        self.downsample=downsample\n        self.stride=stride\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        identity=x\n        out=self.conv1(x)\n        out=self.b1(out)\n        out=self.relu(out)\n        out=self.conv2(out)\n        out=self.b2(out)\n        out=self.relu(out)\n        out=self.conv3(out)\n        out=self.b3(out)\n        if self.downsample is not None:\n            identity=self.downsample(x)\n        out+=identity\n        out=self.relu(out)\n        return out\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T16:46:53.128867Z","iopub.execute_input":"2025-08-23T16:46:53.130702Z","iopub.status.idle":"2025-08-23T16:46:53.143605Z","shell.execute_reply.started":"2025-08-23T16:46:53.130640Z","shell.execute_reply":"2025-08-23T16:46:53.142024Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"class TinyResNet(nn.Module):\n    def __init__(self):\n        super(TinyResNet, self).__init__()\n        self.in_channels=64\n        self.conv1=nn.Conv2d(3,64,kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn=nn.BatchNorm2d(64)\n        self.relu=nn.ReLU()\n        downsample= nn.Sequential(nn.Conv2d(64,256,kernel_size=2, stride=2, bias=False),\n                                 nn.BatchNorm2d(256))\n        self.layer1=BottleNeck(64,64, stride=2, downsample=downsample)\n\n    def forward(self, x):\n        x=self.conv1(x)\n        x=self.bn(x)\n        x=self.relu(x)\n        x=self.layer1(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T16:50:29.338844Z","iopub.execute_input":"2025-08-23T16:50:29.339275Z","iopub.status.idle":"2025-08-23T16:50:29.347545Z","shell.execute_reply.started":"2025-08-23T16:50:29.339249Z","shell.execute_reply":"2025-08-23T16:50:29.346396Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"from torchsummary import summary\nimport torch\nimport torch.nn as nn\n\n# Assuming your model class TinyResNet is defined\nmodel = TinyResNet()\n\n# Move model to the device (CPU or CUDA)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Print model summary for input size (e.g., RGB images 3x224x224)\nsummary(model, input_size=(3, 224, 224))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T16:50:31.553283Z","iopub.execute_input":"2025-08-23T16:50:31.553571Z","iopub.status.idle":"2025-08-23T16:50:31.619148Z","shell.execute_reply.started":"2025-08-23T16:50:31.553552Z","shell.execute_reply":"2025-08-23T16:50:31.618213Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 112]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 112]             128\n              ReLU-3         [-1, 64, 112, 112]               0\n            Conv2d-4         [-1, 64, 112, 112]           4,096\n       BatchNorm2d-5         [-1, 64, 112, 112]             128\n              ReLU-6         [-1, 64, 112, 112]               0\n            Conv2d-7           [-1, 64, 56, 56]          36,864\n       BatchNorm2d-8           [-1, 64, 56, 56]             128\n              ReLU-9           [-1, 64, 56, 56]               0\n           Conv2d-10          [-1, 256, 56, 56]          16,384\n      BatchNorm2d-11          [-1, 256, 56, 56]             512\n           Conv2d-12          [-1, 256, 56, 56]          65,536\n      BatchNorm2d-13          [-1, 256, 56, 56]             512\n             ReLU-14          [-1, 256, 56, 56]               0\n       BottleNeck-15          [-1, 256, 56, 56]               0\n================================================================\nTotal params: 133,696\nTrainable params: 133,696\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 78.09\nParams size (MB): 0.51\nEstimated Total Size (MB): 79.18\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":78}]}